{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7632003-9a2d-4185-880d-b57b9cabbae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/jovyan/mi-drive/medinfo_lab/Research_Projects/zhang/Husky/tools/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7dca1e2-31f1-45a9-af8b-4d61df2636eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '4'\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from Model.base.RoBERTa.data.mlm_dataset import *\n",
    "from Model.base.RoBERTa.layers.Roberta_mlm import RobertaMlm\n",
    "\n",
    "\n",
    "if Debug:\n",
    "    print('开始训练 %s' % get_time())\n",
    "onehot_type = False\n",
    "roberta = RobertaMlm().to(device)\n",
    "if Debug:\n",
    "    print('Total Parameters:', sum([p.nelement() for p in roberta.parameters()]))\n",
    "\n",
    "if UsePretrain and os.path.exists(PretrainPath):\n",
    "    if SentenceLength == 512:\n",
    "        print('开始加载预训练模型！')\n",
    "        roberta.load_pretrain(SentenceLength)\n",
    "        print('完成加载预训练模型！')\n",
    "    else:\n",
    "        print('开始加载本地模型！')\n",
    "        roberta.load_pretrain(SentenceLength)\n",
    "        print('完成加载本地模型！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2178027-5491-457d-b5fd-1f91218f0e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "dataset = load_dataset(\"text\", data_files=CorpusPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685e0eae-0730-409a-b2a6-d2fa5735d192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 197374098\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ec2bed-dac5-4355-88df-7172235452c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_size = 510\n",
    "def chunk_examples(examples):\n",
    "    chunks = []\n",
    "    for sentence in examples['summary']:\n",
    "        chunks += [sentence[i:i+window_size] for i in range(0, len(sentence) - window_size + 1, 510)]\n",
    "    return {\"chunks\": chunks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9c2bbb-1d9a-4781-85fc-c32692aacb96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 µs, sys: 22 µs, total: 35 µs\n",
      "Wall time: 32.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c875d07b-6d2c-4bda-909c-bb17dd5e8ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.map(chunk_examples, batched=True, remove_columns=train_data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d237aa8d-efb2-4ca1-a269-ef6601bb46c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80957it [01:55, 700.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = RobertaDataSet(train_data['chunks'][:-1], onehot_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "416a36ff-fd65-4f16-8213-3dd9403bd582",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[100]['input_token_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37072743-23cb-4e6f-b279-5a3482b777ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[100]['token_ids_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e752d0bf-5a48-4895-a46c-f47c61b6c6de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[100]['segment_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "def3db1c-ea8a-4e44-97fa-048af5389a39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=train_data, batch_size=BatchSize, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ebb0a0-a211-436c-b4f8-e264b77cb19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   1%|| 21/1423 [00:12<13:27,  1.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m print_loss \u001b[38;5;241m=\u001b[39m mask_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     28\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m \u001b[43mmask_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Debug:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim = Adam(roberta.parameters(), lr=MLMLearningRate)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "for epoch in range(MLMEpochs):\n",
    "    # train\n",
    "    if Debug:\n",
    "        print('第%s个Epoch %s' % (epoch, get_time()))\n",
    "    roberta.train()\n",
    "    data_iter = tqdm(enumerate(dataloader),\n",
    "                        desc='EP_%s:%d' % ('train', epoch),\n",
    "                        total=len(dataloader),\n",
    "                        bar_format='{l_bar}{r_bar}')\n",
    "    print_loss = 0.0\n",
    "    for i, data in data_iter:\n",
    "        if Debug:\n",
    "            print('生成数据 %s' % get_time())\n",
    "        data = {k: v.to(device) for k, v in data.items()}\n",
    "        input_token = data['input_token_ids']\n",
    "        segment_ids = data['segment_ids']\n",
    "        label = data['token_ids_labels']\n",
    "        if Debug:\n",
    "            print('获取数据 %s' % get_time())\n",
    "        mlm_output = roberta(input_token, segment_ids).permute(0, 2, 1)\n",
    "        if Debug:\n",
    "            print('完成前向 %s' % get_time())\n",
    "        mask_loss = criterion(mlm_output, label)\n",
    "        print_loss = mask_loss.item()\n",
    "        optim.zero_grad()\n",
    "        mask_loss.backward()\n",
    "        optim.step()\n",
    "        if Debug:\n",
    "            print('完成反向 %s\\n' % get_time())\n",
    "\n",
    "    print('EP_%d mask loss:%s' % (epoch, print_loss))\n",
    "\n",
    "    # save\n",
    "    output_path = FinetunePath + '.ep%d' % epoch\n",
    "    torch.save(roberta.cpu(), output_path)\n",
    "    roberta.to(device)\n",
    "    print('EP:%d Model Saved on:%s' % (epoch, output_path))\n",
    "\n",
    "    # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b85df3-9995-4194-b880-58b6fcbbb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485147fb-7d25-46b0-83cd-00d21df7b0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
